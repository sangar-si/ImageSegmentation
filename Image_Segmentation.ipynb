{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "11eVGcPYX-XcyZdtDtDYOQDEmEbnLgO7b",
      "authorship_tag": "ABX9TyOfPfoCH4adHxO/OnVkObTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangar-si/ImageSegmentation/blob/main/Image_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and extract dataset"
      ],
      "metadata": {
        "id": "Mng3v2uN7J6r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qH9jRdz440N"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/Data/kaggle.json /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c carvana-image-masking-challenge\n",
        "!cp /content/drive/MyDrive/Data/extract.sh /content/extract.sh\n",
        "!sh extract.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, RMSprop\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from os import listdir\n",
        "from os.path import splitext\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "mTv8rdhJJdAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('metadata.csv')"
      ],
      "metadata": {
        "id": "eIOwcDe2MWY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset class"
      ],
      "metadata": {
        "id": "O52c8Jys7Tbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = \"/content/train\"\n",
        "mask_dir = \"/content/train_masks\"\n",
        "img_path = Path(images_dir)\n",
        "\n",
        "class LoadData(Dataset):\n",
        "  def __init__(self,img_path, mask_path, scale = 1):\n",
        "    self.img_path = Path(img_path)\n",
        "    self.mask_path = Path(mask_path)\n",
        "    self.scale = scale\n",
        "    self.img_id = [splitext(f)[0] for f in listdir(img_path) if not f.startswith(\".\")]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_id)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    name = self.img_id[idx]\n",
        "    mask_file = list(self.mask_path.glob(name +\"_mask\" +'.*'))\n",
        "    img_file = list(self.img_path.glob(name+'.*'))\n",
        "    mask = self.load(mask_file[0])\n",
        "    img = self.load(img_file[0])\n",
        "    mask = self.preprocess(img = mask, scale = self.scale, is_mask = True)\n",
        "    img = self.preprocess(img = img, scale = self.scale, is_mask = False)\n",
        "\n",
        "    return {\n",
        "        'image': torch.as_tensor(img.copy()).float().contiguous(),\n",
        "        'mask' : torch.as_tensor(mask.copy()).long().contiguous()\n",
        "    }\n",
        "  @classmethod\n",
        "  def load(cls,filename):\n",
        "    return Image.open(filename)\n",
        "\n",
        "  @classmethod\n",
        "  def preprocess(cls,img,scale,is_mask):\n",
        "    w, h = img.size\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    img = img.resize((new_w, new_h), resample=Image.NEAREST if is_mask else Image.BICUBIC)\n",
        "    img_arr = np.asarray(img)\n",
        "    if img_arr.ndim == 2 and not is_mask:\n",
        "      img_arr = img_arr[np.newaxis, ...]\n",
        "    elif not is_mask:\n",
        "      img_Arr = img_arr.transpose((2,0,1))\n",
        "    if not is_mask:\n",
        "      img_arr = img_arr / 255\n",
        "    return img_arr\n"
      ],
      "metadata": {
        "id": "jSgYxxoc2qDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = LoadData(img_path = images_dir, scale = 0.5, mask_path= mask_dir)"
      ],
      "metadata": {
        "id": "ylSH_w1W3AfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.matshow(np.asarray(ds[1]['mask']))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "P6qyIFhFpbK4",
        "outputId": "15d73961-e238-4452-963b-9d0efd8e0689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 431.55x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNet model definition"
      ],
      "metadata": {
        "id": "g0YOO0ne7cpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "\n",
        "class EnBlock(nn.Module):\n",
        "  def __init__(self, in_ch, out_ch):\n",
        "    super().__init__()\n",
        "    self.convBlock = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.ReLU(), nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.ReLU())\n",
        "  def forward(self, x):\n",
        "    return self.convBlock(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, chnls = (3,64,128,256,512,1024)):\n",
        "    super().__init__()\n",
        "    self.en_blocks = nn.ModuleList([EnBlock(chnls[i], chnls[i+1]) for i in range(len(chnls)-1)])\n",
        "    self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    enc_features = []\n",
        "    for block in self.en_blocks:\n",
        "      x = block(x)\n",
        "      enc_features.append(x)\n",
        "      x = self.pool(x)\n",
        "    return enc_features\n",
        "\n",
        "class DeBlock(nn.Module):\n",
        "  def __init__(self, in_ch, out_ch):\n",
        "    super().__init__()\n",
        "    self.upConv = nn.ConvTranspose2d(in_ch, out_ch, 2, 2)\n",
        "    self.decBlock = EnBlock(in_ch, out_ch)\n",
        "\n",
        "  def crop(self, enc_features, x):\n",
        "    _,_,h,w = x.shape\n",
        "    enc_features   = torchvision.transforms.CenterCrop([h, w])(enc_features) \n",
        "    return x, enc_features\n",
        "\n",
        "  def pad(self, enc_features, x):\n",
        "    _,_,hx,wx = x.shape\n",
        "    _,_,henc,wenc = enc_features.shape\n",
        "    hdiff = henc - hx\n",
        "    wdiff = wenc - wx\n",
        "    x = F.pad(x, [wdiff // 2, wdiff - wdiff // 2,\n",
        "                        hdiff // 2, hdiff - hdiff // 2])\n",
        "    return x, enc_features\n",
        "\n",
        "  def forward(self, x, enc_features):\n",
        "    x = self.upConv(x)\n",
        "    # x, enc_f = self.crop(enc_features,x)\n",
        "    x, enc_f = self.pad(enc_features, x)\n",
        "    x = torch.cat([x, enc_f], dim=1)\n",
        "    x = self.decBlock(x)\n",
        "    return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, chnls = (1024, 512, 256, 128, 64)):\n",
        "    super().__init__()\n",
        "    self.chnls = chnls\n",
        "    self.de_blocks = nn.ModuleList([DeBlock(chnls[i], chnls[i+1]) for i in range(len(chnls)-1)])\n",
        "\n",
        "  def forward(self,x,enc_features):\n",
        "    for i in range(len(self.chnls)-1):\n",
        "      x = self.de_blocks[i](x, enc_features[i])\n",
        "    return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self, enc_chnls = (3,64,128,256,512,1024), dec_chnls = (1024, 512, 256, 128, 64), num_class = 1, retain_dim=False, out_sz=(572,572)):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(enc_chnls)\n",
        "    self.decoder = Decoder(dec_chnls)\n",
        "    self.head = nn.Conv2d(dec_chnls[-1],num_class, 1)\n",
        "    self.retain_dim = retain_dim\n",
        "    self.out_sz = out_sz\n",
        "  \n",
        "  def forward(self,x):\n",
        "    enc_features = self.encoder(x)\n",
        "    out = self.decoder(enc_features[::-1][0], enc_features[::-1][1:])\n",
        "    out = self.head(out)\n",
        "    if self.retain_dim:\n",
        "      out = F.interpolate(out, self.out_sz)\n",
        "    return out\n",
        "\n",
        "class CEDiceLoss(nn.Module):\n",
        "  def __init__(self, weights = None, size_average = True):\n",
        "    super(CEDiceLoss,self).__init__()\n",
        "\n",
        "  def dice(self, mask_pred, mask_true, smooth=1e-8):\n",
        "    mask_pred = F.softmax(mask_pred).float()\n",
        "    mask_true = F.one_hot(mask_true, 2).permute(2, 0, 1).float()\n",
        "    # print(mask_pred.shape)\n",
        "    # print(mask_true.shape)\n",
        "    mask_pred = mask_pred.reshape(-1)\n",
        "    mask_true = mask_true.reshape(-1)\n",
        "    intersection = (mask_pred * mask_true).sum()\n",
        "    dice_loss = 1 - (2 * intersection + smooth) / (mask_pred.sum() + mask_true.sum() + smooth)\n",
        "    return dice_loss\n",
        "\n",
        "  def forward(self, mask_pred, mask_true, smooth = 1e-8):\n",
        "    CELoss = F.cross_entropy(mask_pred, mask_true, reduction='mean')\n",
        "    dice_sum = 0\n",
        "    for i in range(mask_pred.shape[0]):\n",
        "      dice_sum+= self.dice(mask_pred[i,...], mask_true[i,...])\n",
        "    dice_loss = dice_sum/mask_pred.shape[0]\n",
        "    # mask_pred = F.softmax(mask_pred)\n",
        "    # mask_pred = mask_pred.view(-1)\n",
        "    # mask_true = mask_true.view(-1)\n",
        "    # intersection = (mask_pred * mask_true).sum()\n",
        "    # dice_loss = 1 - (2 * intersection + smooth) / (mask_pred.sum() + mask_true.sum() + smooth)\n",
        "    return CELoss+dice_loss\n",
        "\n",
        "def dice_score(mask_pred, mask_true, smooth = 1e-8):\n",
        "  dice_sum = 0.0\n",
        "  for i in range(mask_pred.shape[0]):\n",
        "    m_pred = mask_pred[i,...]\n",
        "    m_true = mask_true[i,...]\n",
        "    m_pred = F.one_hot(m_pred.argmax(dim = 0), 2).permute(2,0,1).float().reshape(-1)\n",
        "    m_true = F.one_hot(m_true,2).permute(2,0,1).float().reshape(-1)\n",
        "    intersection = (m_pred * m_true).sum()\n",
        "    dice_sum += 1 - (2 * intersection + smooth) / (m_pred.sum() + m_true.sum() + smooth)\n",
        "  return dice_sum/mask_pred.shape[0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yyRUHLwvukPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, eval and predict function"
      ],
      "metadata": {
        "id": "PbxFg3uS7iTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, epochs, batch_size, lr, device, scale, val_percent, amp, save_checkpoint = True):\n",
        "  images_dir = \"/content/train\"\n",
        "  mask_dir = \"/content/train_masks\"\n",
        "  img_path = Path(images_dir)\n",
        "  ds = LoadData(img_path = images_dir, scale = scale, mask_path= mask_dir)\n",
        "\n",
        "  n_val = int(len(ds) * val_percent)\n",
        "  n_train = len(ds) - n_val\n",
        "  train_set, val_set = random_split(ds, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "  loader_args = dict(batch_size = batch_size, num_workers = 4, pin_memory = True)\n",
        "  train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
        "  val_loader = DataLoader(val_set, shuffle=False, drop_last = True, **loader_args) \n",
        "\n",
        "  optimizer = RMSprop(net.parameters(), lr = lr, weight_decay = 1e-8, momentum = 0.9)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
        "  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
        "  # criterion = nn.CrossEntropyLoss()\n",
        "  criterion = CEDiceLoss()\n",
        "  global_step = 0\n",
        "  epoch_loss = 0\n",
        "  val_score = {}\n",
        "  for epoch in range(epochs):\n",
        "    net.train()\n",
        "    with tqdm(total = n_train, desc = f'Epoch {epoch + 1}/{epochs}', unit = 'img') as pbar:\n",
        "      for batch in train_loader:\n",
        "        imgs = batch['image']\n",
        "        masks = batch['mask']\n",
        "        imgs = imgs.to(device=device, dtype = torch.float32)\n",
        "        imgs = torch.permute(imgs,(0,3,1,2))\n",
        "        masks = masks.to(device=device, dtype = torch.long)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled = amp):\n",
        "          masks_pred = net(imgs)\n",
        "          # loss = criterion(masks_pred, masks)\\\n",
        "          #                  + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
        "          #                              F.one_hot(masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
        "          #                              multiclass=True)\n",
        "          loss = criterion(masks_pred,masks)\n",
        "        optimizer.zero_grad(set_to_none = True)\n",
        "        grad_scaler.scale(loss).backward()\n",
        "        grad_scaler.step(optimizer)\n",
        "        grad_scaler.update()\n",
        "\n",
        "        pbar.update(imgs.shape[0])\n",
        "        global_step +=1\n",
        "        epoch_loss += loss.item()\n",
        "        pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
        "\n",
        "        #Eval\n",
        "        div_step = (n_train//(10*batch_size))\n",
        "        if div_step > 0:\n",
        "          if global_step % div_step == 0:\n",
        "            val_score = evaluate(net, val_loader, device)\n",
        "            print(\"Val score is \", val_score)\n",
        "            scheduler.step(val_score)\n",
        "    if save_checkpoint:\n",
        "      try:\n",
        "        torch.save(net.state_dict(),\"unet\"+str(epoch)+\".pth\")\n",
        "      except:\n",
        "        print(\"Save failed\")\n",
        "\n",
        "def evaluate(net, data_loader, device):\n",
        "  net.eval()\n",
        "  dice_score_value = 0 \n",
        "  for batch in tqdm(data_loader, total = len(data_loader), desc = 'Validation round', unit = 'batch'):\n",
        "    imgs, masks = batch['image'], batch['mask']\n",
        "    imgs = imgs.to(device=device, dtype = torch.float32)\n",
        "    imgs = torch.permute(imgs,(0,3,1,2))\n",
        "    masks = masks.to(device=device, dtype = torch.long)\n",
        "    # masks = F.one_hot(masks, 2).permute(0, 3, 1, 2).float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      mask_pred = net(imgs)\n",
        "      dice_score_value += dice_score(mask_pred, masks)\n",
        "    net.train()\n",
        "  return dice_score_value/len(data_loader)\n"
      ],
      "metadata": {
        "id": "8kt4vXAZYPVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(net, image, device):\n",
        "  net.eval()\n",
        "  image = image.to(device = device, dtype = torch.float32)\n",
        "\n",
        "  image = image[None,:]\n",
        "  image = torch.permute(image, (0,3,1,2))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    m_pred = net(image)\n",
        "  m_pred = m_pred[0,...].argmax(dim=0).to(device = 'cpu', dtype = torch.long)\n",
        "  plt.matshow(np.asarray(m_pred))\n",
        "  plt.show()\n",
        "  return m_pred\n",
        "\n",
        "def display_mask(mask):\n",
        "  plt.matshow(np.asarray(mask))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "KfPb9qjHx7kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = UNet(num_class=2)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net.to(device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvaDIzAx6IO6",
        "outputId": "fcefa313-29d6-4702-a5f1-b84496e92ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-94166ed2641d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'UNet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(net=net, epochs = 3, batch_size = 5, lr = 0.00001, device = device, scale = 0.5, val_percent = 10/100, amp = False)"
      ],
      "metadata": {
        "id": "NLrUYE6bpugV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(val_set, shuffle=False, drop_last = True, **loader_args)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "test_image = val_set[10]\n",
        "test_img = test_image['image']\n",
        "test_mask = test_image['mask']\n",
        "m_pred = predict(net, test_img, device)\n",
        "display_mask(test_mask)"
      ],
      "metadata": {
        "id": "vlXIyva7nzIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4gJYGuCnIrfl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}